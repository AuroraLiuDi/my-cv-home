---
title: Involvement of speech production knowledge in the process of perception
subtitle: Essay for Psychology of Language tutorial
date: 2022-10-06T09:17:22.640Z
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
---
Psycholinguists have a long-standing interest in the relationship between speech perception and production. Speech perception is a process of mapping acoustic signals to linguistic elements including phonemes and distinctive features, and speech production is the motor process of articulation. These two processes are highly connected. The Dual Stream Model suggests that the sensory track of speech sound is used to guide the correct production of speech gestures (Hickok & Poeppel, 2007), indicating that speech information flows forward from auditory areas into motor areas. It remains rather controversial whether flows from the other direction, that speech production knowledge is involved in the speech perception process, also exists. 

Growing theories and evidence suggest that the motor system might be functional in the speech perception process. For example, motor theory of speech perception, one initial attempt at describing this link, claims that speech perception is directly mediated by a phonetic gestural code, which is the representation of motor commands (i.e., ‘tongue backing’) underlying movements for the articulation that primarily define the organization of phonemes. Motor system is required in the speech perception to analyze the motor properties of acoustic signals and transform them into phonetic representations (Liberman & Mattingly, 1985). Primary empirical evidence supporting the interaction is gained from aphasia patients. Some patients (i.e., Broca’s aphasia and conduction aphasia) with lesions in the left frontal or left frontoparietal lobe, overlapping with the dorsal stream representing articulatory information defined in the Dual Stream Model, have shown deficits in auditory monitoring tasks, including phoneme discrimination (i.e., differentiating between ‘cat’ and ‘cot’), while remains intact in semantic matching (i.e., match ‘cat’ to the picture of a cat). These findings might result from the impairment of auditory-verbal short-term memory, which recruits the dorsal stream, as the patients potentially fail to preserve the acoustic information for discrimination. Another non-mutually exclusive interpretation is that the online segmentation of syllables in the speech perception might be facilitated by the information provided by its articulatory counterparts (Hickok & Poeppel, 2007). These prior attempts have illustrated the possibility that knowledge of speech production might be activated in the process of speech perception. However, the neural mediation mechanism underlying this interaction is not yet clear. 

Neurological evidence further refines the proposed interaction between speech perception and motor knowledge discovered at behavioural level. One study using transcranial magnetic stimulation (TMS) has shown that by specifically enhancing activities on the motor cortex controlling the lip or tongue, corresponding performance in distinguishing labial or dental sounds is also improved, while the differentiating of discordant articulations is inhabited, suggesting the motor system facilitates the analysis of phonological components (D'Ausilio et al., 2009). Functional magnetic resonance imaging (fMRI) studies have generalized the interaction between motor and auditory systems to other paradigms that do not involve active phonological discrimination. One experiment identified overlapping activated areas (biliteral posterior portion of ventral premotor cortex) between a passive listening and a production condition, indicating that speech production knowledge is involved in a general auditory-to-articulatory mapping process (Wilson et al., 2004). The overlapping regions shown in fMRI evidence might not be necessary to either speech perception or production, but rather be involved in a confounding process, such as the retrieval of phonological representations, that correlates with both processes. Given this possibility, evidence acquired using higher temporal accuracy methodologies is necessary. A review of studies combining fMRI, electroencephalogram (EEG), and magnetoencephalography (MEG) suggests the activation of auditory and somatosensory cortex in the passive listening task are synchronized, confirming the results of fMRI studies (Liebenthal & Möttönen, 2018). 

Several concerns, on the other hand, are raised to cast doubt on the validity of evidence supporting the interaction between speech production and perception. Firstly, the coactivation of motor and auditory areas is not restricted to speech perception but is triggered by non-verbal sounds as well. This domain-general co-activation might suggest that the brain regions identified in the neuroimaging studies are involved only in the lower-order processing of acoustic information. Another concern is speech production is only a modulating factor other than a necessary factor of speech perception. In the left frontal brain-lesion cases, aphasia patients experiencing speech production loss still preserves speech recognition; similarly, in the Wada procedure, where the left hemisphere of participants is selectively anesthetized, subjects’ ability to distinguish target word from the phonological distractor remains in the picture-matching paradigm (Kemmerer, 2014). These potential concerns are also problematic. The dorsal stream underlying speech production does not solely involve the left frontal lesion. Some portions of motor regions might be left spared in these cases, allowing for the involvement of articulatory information in speech perception. Additionally, the ability to match words with pictures among phonological distractors does not necessarily involve phonology discrimination, as patients found with dissociation between comprehension and phonological discrimination also behaves as normal in the picture-matching paradigm. 

One more valid evidence, suggesting that speech production knowledge might not be necessary to perception, is that infants with no prior articulatory knowledge also exhibit perception abilities, such as categorical perception (Kemmerer, 2014). Carried out in a left-lateralized higher-order organization, categorical effect refers to the ability to identify classification boundaries on a continuum of familiar acoustic stimuli. Based on this concern, a compromised view of the interaction between speech production and perception can be made to be compatible with more existing evidence. The refined model suggests that the motor system is activated to only aid the discrimination ambiguous acoustic patterns. The activation is less prominent when the object of perception is invariant. Categorical perception is less sophisticated and can be made based on acoustic properties alone without involvement of motor cortices. This model, however, still requires a better-defined measurement of acoustic information ambiguity in order to clarify the ranges of tasks that involve knowledge of speech production in perception. 

References

D'Ausilio, A., Pulvermüller, F., Salmas, P., Bufalari, I., Begliomini, C., & Fadiga, L. (2009). The motor somatotopy of speech perception. *Current biology*, *19*(5), 381-385. 

Hickok, G., & Poeppel, D. (2007). The cortical organization of speech processing. *Nature Reviews Neuroscience*, *8*(5), 393-402. 

Kemmerer, D. (2014). *Cognitive neuroscience of language*. Psychology Press. 

Liberman, A. M., & Mattingly, I. G. (1985). The motor theory of speech perception revised. *Cognition*, *21*(1), 1-36. 

Liebenthal, E., & Möttönen, R. (2018). An interactive model of auditory-motor speech perception. *Brain and language*, *187*, 33-40. 

Wilson, S. M., Saygin, A. P., Sereno, M. I., & Iacoboni, M. (2004). Listening to speech activates motor areas involved in speech production. *Nature neuroscience*, *7*(7), 701-702.